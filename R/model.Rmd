---
title: "BulsinkB xG Model"
author: "Philip Bulisnk"
date: "21/09/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#library(BulsinkBxG)
#source("~/GitHub/BulsinkBxG/R/data.R")
#source("~/GitHub/BulsinkBxG/R/scrape.R")
library(dplyr)

```

#Intro

This document will outline the creating of a xG model for use in the BulsinkB model (see [twitter.com/BulsinkB](https://www.twitter.com/BulsinkB)). This model bulding will use the tidymodels toolset and be based on excellent work by Matt Barlowe and Evolving Wild. 

#Data

We'll start by loading data using the tools in this package, then combining all but the most recent season's data into one file:
```{r data_load}
pbp2007<-readRDS("~/NHLpbp/2007.rds")
pbp2008<-readRDS("~/NHLpbp/2008.rds")
pbp2009<-readRDS("~/NHLpbp/2009.rds")
pbp2010<-readRDS("~/NHLpbp/2010.rds")
pbp2011<-readRDS("~/NHLpbp/2011.rds")
pbp2012<-readRDS("~/NHLpbp/2012.rds")
pbp2013<-readRDS("~/NHLpbp/2013.rds")
pbp2014<-readRDS("~/NHLpbp/2014.rds")
pbp2015<-readRDS("~/NHLpbp/2015.rds")
pbp2016<-readRDS("~/NHLpbp/2016.rds")
pbp2017<-readRDS("~/NHLpbp/2017.rds")
pbp2018<-readRDS("~/NHLpbp/2018.rds")
#pbp2019<-readRDS("~/NHLpbp/2019.rds")

pbp<-dplyr::bind_rows(pbp2007, pbp2008, pbp2009, pbp2010, pbp2011, pbp2012, pbp2013, pbp2014, pbp2015, pbp2016, pbp2017)#, pbp2018)
pbp_test<-pbp2018

#Get rid of year files: we don't need them in memory anymore
rm(pbp2007, pbp2008, pbp2009, pbp2010, pbp2011, pbp2012, pbp2013, pbp2014, pbp2015, pbp2016, pbp2017, pbp2018, pbp2019)
```

Note that we'll use 2019 (current season) data as the test to see how well the model predicts. How much data do we have? The number of events in the training (2007 - 2018) data is `r nrow(pbp)` and the number of rows in the testing 2019 data is `r nrow(pbp_test)`

Now some more shortcut prep:
```{r prep}
fenwick_events <- c('SHOT', 'MISS', 'GOAL')
corsi_events <- c('SHOT', 'MISS', 'GOAL', 'BLOCK')
```

##Data Munching
We'll use Fenwick data here: the NHL PBP doesn't provide the shooter location on a shot-block event. So we'll start paring down the data. Note that we're also selecting the immediately preceding event for some feature testing down the road.

```{r fenwick_cut}
pbp<-pbp %>%
  filter(coords_x != 'NA' & coords_y != "NA" & event_detail != "NA" & event_team != "NA") %>%
  filter(event_type %in% fenwick_events | dplyr::lag(event_type %in% fenwick_events)) %>%
  select(-c(session, event_zone, event_length, num_on, num_off, players_on, players_off, game_score_state, game_strength_state))

pbp_test<-pbp_test %>%
  filter(coords_x != 'NA' & coords_y != "NA" & event_detail != "NA" & event_team != "NA") %>%
  filter(event_type %in% fenwick_events | dplyr::lag(event_type %in% fenwick_events)) %>%
  select(-c(session, event_zone, event_length, num_on, num_off, players_on, players_off, game_score_state, game_strength_state))
```

That has quickly reduced our data size: we now have `r nrow(pbp)` training rows and `r nrow(pbp_test)` test rows.

We'll now move on by adding a bunch of data columns (and maybe dropping a few too). This feature addition is not changing the data, but just re-phrasing it in a way that a model can use it to make predictions. This is where the 'art' of data science lives.

```{r features}
prep_data<-function(data){
  data<- data %>%
    mutate(is_home = if_else(event_team == home_team, 1, 0),  # binary home team event factor
           is_goal = if_else(event_type == "GOAL", 1, 0),  # binary is goal factor
           x_coord = abs(coords_x),  # absolute x coordinate - put home and away on same side of ice
           y_coord = if_else(coords_x < 0, coords_y * -1, coords_y)) %>%  # absolute y coordinate - for calculations
  #calculate time_diff but only use the game, don't revert to previous game in data stack
    group_by(game_id) %>%
      arrange(event_index, .by_group = TRUE) %>%
      mutate(time_diff = game_seconds - dplyr::lag(game_seconds)) %>%  # calculate time from previous event
    ungroup() %>%
    mutate(time_diff = if_else(is.na(time_diff), 100, time_diff),  # fix any NA results - 100 s will have such low impact on values.
           time_diff = if_else(time_diff < 0, 1000, time_diff)) %>%  # <0 time diff makes no sense, bump it to the psudo na value of 100 s
    mutate(is_rebound = if_else(time_diff < 3 & event_type %in% fenwick_events & dplyr::lag(event_type) %in% corsi_events & event_team == dplyr::lag(event_team), 1, 0),  # is this a rebound shot?
           is_rush = if_else(time_diff < 4 & abs(dplyr::lag(coords_x)) < 25, 1, 0),  # does this look like a shot on a rush?
           speed = if_else(!is.na(time_diff), sqrt((coords_x-dplyr::lag(coords_x))^2 + (coords_y - dplyr::lag(coords_y))^2)/time_diff, 0),  # speed from previous event to shot location in m/s
           shot_side = if_else((coords_x < 0 & coords_y < 0) | (coords_x > 0 & coords_y > 0), 'right', 'left'),  # from which side (goalie view) the fenwick comes from
           cross_ice = if_else(shot_side == dplyr::lag(shot_side), 1, 0)) %>%  # if shot comes from opposite side of previous event
  #Fixing any NA results or other illogicals
    mutate(is_rush = if_else(is.na(is_rush), 0, is_rush), 
           is_rebound = if_else(is.na(is_rebound), 0, is_rebound),
           is_cluster = if_else(lag(is_rebound)==1 & is_rebound == 1, 1, 0),
           speed = if_else(is.na(speed), 0, speed),
           speed = if_else(is.infinite(speed), 0, speed),
           shot_side = if_else(is.na(shot_side), 'middle', shot_side),
           cross_ice = if_else(is.na(cross_ice), 0, cross_ice),
           #pbp_distance from EW
           pbp_distance = suppressWarnings(as.numeric(sub(".*Zone, *(.*?) * ft.*", "\\1", event_description))),
           #event_zone from EW
           event_zone = ifelse((grepl("off. zone", tolower(event_description)) == TRUE), "Off", 
                                 ifelse((grepl("neu. zone", tolower(event_description)) == TRUE), "Neu", 
                                        ifelse((grepl("def. zone", tolower(event_description)) == TRUE), "Def", 
                                               NA))),  
           event_zone = ifelse(event_zone == "Def" & event_type == "BLOCK", "Off", event_zone), 
           event_zone = ifelse(event_type %in% fenwick_events & event_zone == "Def" & pbp_distance <= 64, "Off", event_zone)) %>%
  #We've done our manipulations using the lagged data, go to fenwick only data now (and drop shootout attempts for which game_seconds == 3900)
    filter(event_type %in% fenwick_events & game_seconds != 3900) %>%
    mutate(shot_angle = if_else(abs(coords_y) < 3, 0, if_else(coords_y > 0,
                                                              abs(atan((coords_y - 3) / (89 - abs(coords_x))) * (180 / pi)),
                                                              abs(atan((coords_y + 3) / (89 - abs(coords_x))) * (180 / pi)))),# angle to the closest post if outside 
           
           shot_distance = sqrt((89 - abs(coords_x))^2 + coords_y^2) # distance to the center of the goal mouth TODO: change to nearest post
           ) %>%  
    mutate(# Update distance calc for long shots (and various mistakes) from EW
           shot_distance = if_else(pbp_distance > 89 & event_detail != "Wrap-around" & event_detail != "Tip-In" & event_detail != "Deflected" & !(pbp_distance > 89 & event_zone == "Off"),
                                    sqrt((abs(coords_x) + 89)^2 + coords_y^2), shot_distance),  
           shot_angle = if_else(pbp_distance > 89 & event_detail != "Tip-In" & event_detail !="Wrap-around" & event_detail != "Deflected" & !(pbp_distance > 89 & event_zone == "Off"), 
                                  abs(atan(coords_y / (abs(coords_x) + 89)) * (180 / pi)), shot_angle), 
           event_zone = ifelse(event_zone == "Def" & pbp_distance <= 64, "Off", event_zone))%>%
    mutate(shot_angle = if_else(x_coord >= 89, 90 + shot_angle,shot_angle)) %>% # fix angles for behind-net shots
    mutate(attacker_benefit = if_else(is_home == 1, home_skaters - away_skaters, away_skaters - home_skaters),  # Does the shooting team have more or less players on ice?
           #extra_attacker = if_else((is_home & home_skaters > away_skaters) | (!is_home & away_skaters > home_skaters), 1, 0),
           #shorthanded = if_else((is_home & home_skaters < away_skaters) | (!is_home & away_skaters < home_skaters), 1, 0),
           shooter_net_empty = if_else((is_home == 1 & is.na(home_goalie)) | (!is_home == 1 & is.na(away_goalie)), 1, 0),  # Is the shooter's goalie pulled?
           target_net_empty = if_else((is_home == 1 & is.na(away_goalie)) | (!is_home == 1 & is.na(home_goalie)), 1, 0),  # Is the target goalie pulled?
           shooter_gd = if_else(is_home == 1, home_score - away_score, away_score - home_score),# What's the score impact?
           shooter_goal_differential = case_when(shooter_gd <= -5 ~ "-5+",
                                                 shooter_gd == -4 ~ "-4",
                                                 shooter_gd == -3 ~ "-3",
                                                 shooter_gd == -2 ~ "-2",
                                                 shooter_gd == -1 ~ "-1",
                                                 shooter_gd == 0 ~ "0",
                                                 shooter_gd == 1 ~ "+1",
                                                 shooter_gd == 2 ~ "+2",
                                                 shooter_gd == 3 ~ "+3",
                                                 shooter_gd == 4 ~ "+4",
                                                 shooter_gd >=5 ~ "+5+",
                                                 TRUE ~ "UNK")
           ) %>%
    mutate(result = factor(is_goal, c(0,1), c('no_goal', 'goal')))  # %>%
    #select(season, game_id, game_period, event_type, event_detail, event_team, event_player_1, coords_x, coords_y, home_team, away_team, home_skaters, away_skaters, home_score, away_score, is_home, is_goal, x_coord, y_coord, time_diff, is_rebound, is_rush, speed, shot_side, cross_ice, is_cluster, pbp_distance, event_zone, shot_angle, shot_distance, attacker_benefit, shooter_net_empty, target_net_empty, shooter_goal_differential)
  return(data)
}

pbp <- pbp %>% prep_data()
pbp_test <- pbp_test %>% prep_data()

```

#Modelling
We'll be using the tidymodels package in R to do the actual modeling. There are a few more things to do with the data to prepare it for tidymodels.
Now we'll split the data randomly into in-sample test & train sets, then prepare the general recipe (or formula) that we want to feed into the model.
```{r tidymodel_recipe}
library(tidymodels)

set.seed(seed = 2007)

train_test_split <- initial_split(data = pbp, prop = 0.75)

train_data<-train_test_split %>% training()
test_data<-train_test_split %>% testing()

model_recipe <- 
  recipe(result ~ shot_distance + shot_angle + event_detail + is_rebound + is_rush + is_cluster +
                   shooter_net_empty + target_net_empty + speed + attacker_benefit + event_zone +
                   shooter_goal_differential + shot_side + cross_ice + x_coord + y_coord,
         data = train_data) %>%
  update_role(x_coord, y_coord, new_role = "ID") %>%
  step_string2factor(event_detail, event_zone, shot_side, shooter_goal_differential) %>%
  step_num2factor(is_rebound, transform = function(x) x+1, levels = c("no", "yes")) %>%
  step_num2factor(is_rush, transform = function(x) x+1, levels = c("no", "yes")) %>%
  step_num2factor(shooter_net_empty, transform = function(x) x+1, levels = c("no", "yes")) %>%
  step_num2factor(target_net_empty,transform = function(x) x+1, levels = c("no", "yes")) %>%
  step_num2factor(cross_ice, transform = function(x) x+1, levels = c("no", "yes")) %>%
  step_num2factor(is_cluster,transform = function(x) x+1, levels = c("no", "yes")) %>%
  step_zv(all_predictors())

summary(model_recipe)
```


Now we can define our model (this is the bit that is changeable) then feed that design into the modeling workflow. Then wqe fit it.

```{r model_design}
model <- logistic_reg() %>%
  set_engine('glm')

xg_wflow<-workflow() %>%
  add_model(model) %>%
  add_recipe(model_recipe)

#xg_wflow

xg_fit <- xg_wflow %>%
  fit(data = train_data)

xg_fit %>% 
  pull_workflow_fit() %>% 
  tidy()
```


#Checking Model Output
Does it make sense?

We've saved some data that we can use to test the predictor with. 
```{r check}
pbp_test$xG <- predict(xg_fit, pbp_test, type = "prob")$.pred_goal

avg_xG_by_coord <- pbp_test %>% group_by(x_coord, y_coord) %>%
    summarise(xg = mean(xG))

ggplot(avg_xG_by_coord, aes(x_coord, y_coord, fill = xg)) + geom_raster() +
    scale_fill_gradient(low = 'blue', high = 'red')+
    geom_vline(xintercept = 0, color = 'red') +
    geom_vline(xintercept = 25, color = 'blue') +
    geom_vline(xintercept = 88, color = 'red') +
    xlab('X Coordinates') + ylab('Y Coordinates') +
    labs(title = 'Average xG Value by Coordinate')

```

We'll do some 'goodness of prediction' work now:
```{r roc}
pbp_test %>% roc_curve(result, xG, event_level = 'second') %>% autoplot()
```

This gives us an auc of `r roc_auc(pbp_test, result, xG, event_level = 'second')`. My first attempt at a model had AUC of 0.746 (@git commit ae73f75, glm model). My best attempt is 0.755 (@git commit fb6446b, glm model).

# Look at the Data
Lets take a look at the data from the test year: First player lists
```{r players}
xg_player <- pbp_test %>%
    group_by(event_player_1, event_team) %>%
    summarise( xG = sum(xG), Goals = sum(is_goal), Difference = sum(xG) - sum(is_goal)) %>%
    arrange(desc(xG))
head(xg_player)
player_xg <- lm(Goals ~ xG, data = xg_player)
summary(player_xg)
ggplot(aes(x = xG, y = Goals), data = xg_player) +
    geom_point() + 
    geom_smooth(method = 'lm') +
    labs(title = 'Expected Goals vs Goals by Player')
```

Next, the same by team:
```{r teams}
xg_team <- pbp_test %>%
    group_by(event_team) %>%
    summarise(xG = sum(xG), Goals = sum(is_goal), Difference = sum(xG) - sum(is_goal)) %>%
    arrange(desc(xG))
head(xg_team)
team_xg <- lm(Goals ~ xG, data = xg_team)
summary(team_xg)
ggplot(aes(x = xG, y = Goals), data = xg_team) +
    geom_point() + 
    geom_smooth(method = 'lm') +
    labs(title = 'Expected Goals vs Goals by Team')
```

Next, the same by game, splitting the two teams. This will give us an idea of xg prediction vs actual goals per team.
```{r games}
xg_game <- pbp_test %>%
    group_by(game_id, event_team) %>%
    summarise(xG = sum(xG), Goals = sum(is_goal), Difference = sum(xG) - sum(is_goal)) %>%
    arrange(desc(xG))
head(xg_game)
game_xg <- lm(Goals ~ xG, data = xg_game)
summary(game_xg)
ggplot(aes(x = xG, y = Goals), data = xg_game) +
    geom_point() + 
    geom_smooth(method = 'lm') +
    labs(title = 'Expected Goals vs Goals by Game')
```

Lets look at the predictions of xG wins vs goal wins:
```{r xg_pred_win}
xg_win <- pbp_test %>% 
  group_by(game_id) %>% 
  summarize(
    homeG = sum(is_goal[is_home == 1]), 
    awayG = sum(is_goal[is_home == 0]), 
    home_xg=sum(xG[is_home == 1]), 
    away_xg=sum(xG[is_home == 0]), 
    g_win=ifelse(homeG>awayG, 'home', 'away'), 
    xg_win=ifelse(home_xg>away_xg, 'home', 'away'), 
    agree=g_win==xg_win)
```
It looks like xG predicts winners `r *sum(xg_win$agree)/nrow(xg_win))*100`% of the time.


Conclusion
